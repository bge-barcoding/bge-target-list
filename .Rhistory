species_markers <- within(species_markers, {
species_marker_id <- seq.int(nrow(species_markers))
}) %>%
.[, c(8,1,4,5,3)] %>% # Remove obsolete and rearrange columns
.[complete.cases(.[ , 2]),] # Omit empty species_id's (NAs)
## Write data as csv to output folder
write.csv(species_markers, file=sprintf('%s/results/species_markers.csv', REPO_HOME),
row.names=FALSE, fileEncoding="utf-8")
```
### Load Tree
To perform an analyses on our species we now load the backbone of the NSR. This
is their complete tree, populated with our collected data. Here where we seek
out overlap / gaps between Naturalis and our obtained Public Sequence Data.
```{r tree, include=FALSE}
## Get classification for each obtained record
## Subsequently, fetch the associated marker and database names for each record
tree <- left_join(nsrSpecies[1], nsrBackbone[c(2:9)], by=c("species_id")) %>%
left_join(., species_markers[c("species_id","database_id", "marker_id")],
by=c("species_id")) %>%
left_join(., markers, by=c("marker_id")) %>%
left_join(., databases, by=c("database_id"))
## Sum count of unique records
tree <- tree %>% group_by_all() %>% summarise(.groups="keep", counts = n())
## Set count for non matching species to NA
tree <- within(tree, {
f <- is.na(database_name) == TRUE
counts[f] <- NA
f <- NULL
})
## Remove obsolete and rearrange columns
tree <- tree[,c(2,3,4,5,6,7,8,11,12,13)]
## Save workspace image
save.image(sprintf('%s/.RData', REPO_HOME))
```
View(natSpecies)
View(natSpecimens)
View(nsrBackbone)
View(nsrSpecimens)
View(taxdata)
library(rmarkdown)
install.packages("rmarkdown")
install.packages("rmarkdown")
library(rmarkdown)
library(rmarkdown)
install.packages("rmarkdown")
install.packages("rmarkdown")
library(rmarkdown)
install.packages("rmarkdown", repos = "https://cran.revolutionanalytics.com")
install.packages("rmarkdown", repos = "https://cran.revolutionanalytics.com")
install.packages("rmarkdown", repos = "https://cran.revolutionanalytics.com")
install.packages("rmarkdown", repos = "https://cran.revolutionanalytics.com")
install.packages("rmarkdown", repos = "https://cran.revolutionanalytics.com")
install.packages("rmarkdown", repos = "https://cran.revolutionanalytics.com")
install.packages("rmarkdown", repos = "https://cran.revolutionanalytics.com")
install.packages("C:/Users/naomi/Downloads/SDSFoundations_1.1.zip", repos = NULL, type = "win.binary")
update.packages()
PATH="C:/rtools40/mingw64"
install.packages("rmarkdown", dependencies = TRUE)
library(rmarkdown)
install.packages("data.table", dependencies = TRUE)
library(data.table)
install.packages("taxizedb", dependencies = TRUE)
library(taxizedb)
install.packages("myTAI", dependencies = TRUE)
library(myTAI)
install.packages("tidyr", dependencies = TRUE)
library(tidyr)
install.packages("shiny", dependencies = TRUE)
library(shiny)
install.packages("DT", dependencies = TRUE)
library(DT)
install.packages("plyr", dependencies = TRUE)
library(plyr)
install.packages("dplyr", dependencies = TRUE)
library(dplyr)
install.packages("stringr", dependencies = TRUE)
library(stringr)
install.packages("d3Tree", dependencies = TRUE)
library(d3Tree)
install.packages("billboarder", dependencies = TRUE)
library(billboarder)
install.packages("nbaR", dependencies = TRUE)
library(nbaR)
install.packages("dplyr", dependencies = TRUE)
install.packages("dplyr", dependencies = TRUE)
install.packages("dplyr", dependencies = TRUE)
getwd()
library(rmarkdown)
library(data.table)
library(taxizedb)
library(myTAI)
library(tidyr)
library(shiny)
library(DT)
library(plyr)
library(dplyr)
library(stringr)
library(d3Tree)
library(billboarder)
library(nbaR)
# This should define the root folder of the local copy of the git repository at:
# https://github.com/naturalis/Custom-databases-DNA-sequences, which is
# automatically defined correctly if we run the present code from within a
# local clone of the repo and have set the working directory to the script
# source (in RStudio: Session > Set working directory > To source file location)
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
## Load species and synonyms from the NSR files, respectively
nsrSpecies.file <- sprintf('%s/data/in_files/nsr_species.csv', REPO_HOME)
nsrSpecies <- read.csv(nsrSpecies.file, encoding="UTF-8")
library(rmarkdown)
library(data.table)
library(taxizedb)
library(myTAI)
library(tidyr)
library(shiny)
library(DT)
library(plyr)
library(dplyr)
library(stringr)
library(d3Tree)
library(billboarder)
library(nbaR)
# This should define the root folder of the local copy of the git repository at:
# https://github.com/naturalis/Custom-databases-DNA-sequences, which is
# automatically defined correctly if we run the present code from within a
# local clone of the repo and have set the working directory to the script
# source (in RStudio: Session > Set working directory > To source file location)
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
## Load species and synonyms from the NSR files, respectively
nsrSpecies.file <- sprintf('.s/data/in_files/nsr_species.csv')
nsrSpecies <- read.csv(nsrSpecies.file, encoding="UTF-8")
library(rmarkdown)
library(data.table)
library(taxizedb)
library(myTAI)
library(tidyr)
library(shiny)
library(DT)
library(plyr)
library(dplyr)
library(stringr)
library(d3Tree)
library(billboarder)
library(nbaR)
# This should define the root folder of the local copy of the git repository at:
# https://github.com/naturalis/Custom-databases-DNA-sequences, which is
# automatically defined correctly if we run the present code from within a
# local clone of the repo and have set the working directory to the script
# source (in RStudio: Session > Set working directory > To source file location)
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
## Load species and synonyms from the NSR files, respectively
nsrSpecies.file <- sprintf('./data/in_files/nsr_species.csv')
nsrSpecies <- read.csv(nsrSpecies.file, encoding="UTF-8")
library(rmarkdown)
library(data.table)
library(taxizedb)
library(myTAI)
library(tidyr)
library(shiny)
library(DT)
library(plyr)
library(dplyr)
library(stringr)
library(d3Tree)
library(billboarder)
library(nbaR)
# This should define the root folder of the local copy of the git repository at:
# https://github.com/naturalis/Custom-databases-DNA-sequences, which is
# automatically defined correctly if we run the present code from within a
# local clone of the repo and have set the working directory to the script
# source (in RStudio: Session > Set working directory > To source file location)
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
## Load species and synonyms from the NSR files, respectively
nsrSpecies.file <- sprintf('../data/in_files/nsr_species.csv')
nsrSpecies <- read.csv(nsrSpecies.file, encoding="UTF-8")
library(rmarkdown)
library(data.table)
library(taxizedb)
library(myTAI)
library(tidyr)
library(shiny)
library(DT)
library(plyr)
library(dplyr)
library(stringr)
library(d3Tree)
library(billboarder)
library(nbaR)
# This should define the root folder of the local copy of the git repository at:
# https://github.com/naturalis/Custom-databases-DNA-sequences, which is
# automatically defined correctly if we run the present code from within a
# local clone of the repo and have set the working directory to the script
# source (in RStudio: Session > Set working directory > To source file location)
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
## Load species and synonyms from the NSR files, respectively
nsrSynonyms.file <- sprintf('%s/../data/in_files/nsr_synonyms.csv', REPO_HOME)
nsrSynonyms <- read.csv(nsrSynonyms.file, encoding="UTF-8")
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
setwd("~/Bioinformatica/Github/internship-dna-barcodes")
library(rmarkdown)
library(data.table)
library(taxizedb)
library(myTAI)
library(tidyr)
library(shiny)
library(DT)
library(plyr)
library(dplyr)
library(stringr)
library(d3Tree)
library(billboarder)
library(nbaR)
# This should define the root folder of the local copy of the git repository at:
# https://github.com/naturalis/Custom-databases-DNA-sequences, which is
# automatically defined correctly if we run the present code from within a
# local clone of the repo and have set the working directory to the script
# source (in RStudio: Session > Set working directory > To source file location)
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
## Load species and synonyms from the NSR files, respectively
nsrSynonyms.file <- sprintf('%s/data/in_files/nsr_synonyms.csv', REPO_HOME)
nsrSynonyms <- read.csv(nsrSynonyms.file, encoding="UTF-8")
setwd("~/Bioinformatica/Github/internship-dna-barcodes")
library(rmarkdown)
library(data.table)
library(taxizedb)
library(myTAI)
library(tidyr)
library(shiny)
library(DT)
library(plyr)
library(dplyr)
library(stringr)
library(d3Tree)
library(billboarder)
library(nbaR)
# This should define the root folder of the local copy of the git repository at:
# https://github.com/naturalis/Custom-databases-DNA-sequences, which is
# automatically defined correctly if we run the present code from within a
# local clone of the repo and have set the working directory to the script
# source (in RStudio: Session > Set working directory > To source file location)
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
## Load species and synonyms from the NSR files, respectively
nsrSynonyms.file <- sprintf('%s/data/in_files/nsr_synonyms.csv', REPO_HOME)
nsrSynonyms <- read.csv(nsrSynonyms.file, encoding="UTF-8")
library(rmarkdown)
library(data.table)
library(taxizedb)
library(myTAI)
library(tidyr)
library(shiny)
library(DT)
library(plyr)
library(dplyr)
library(stringr)
library(d3Tree)
library(billboarder)
library(nbaR)
# This should define the root folder of the local copy of the git repository at:
# https://github.com/naturalis/Custom-databases-DNA-sequences, which is
# automatically defined correctly if we run the present code from within a
# local clone of the repo and have set the working directory to the script
# source (in RStudio: Session > Set working directory > To source file location)
setwd('..')
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
## Load species and synonyms from the NSR files, respectively
nsrSynonyms.file <- sprintf('%s/data/in_files/nsr_synonyms.csv', REPO_HOME)
nsrSynonyms <- read.csv(nsrSynonyms.file, encoding="UTF-8")
library(rmarkdown)
library(data.table)
library(taxizedb)
library(myTAI)
library(tidyr)
library(shiny)
library(DT)
library(plyr)
library(dplyr)
library(stringr)
library(d3Tree)
library(billboarder)
library(nbaR)
# This should define the root folder of the local copy of the git repository at:
# https://github.com/naturalis/Custom-databases-DNA-sequences, which is
# automatically defined correctly if we run the present code from within a
# local clone of the repo and have set the working directory to the script
# source (in RStudio: Session > Set working directory > To source file location)
setwd('..')
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
## Load species and synonyms from the NSR files, respectively
nsrSynonyms.file <- sprintf('%s/data/in_files/nsr_synonym.csv', REPO_HOME)
nsrSynonyms <- read.csv(nsrSynonyms.file, encoding="UTF-8")
library(rmarkdown)
library(data.table)
library(taxizedb)
library(myTAI)
library(tidyr)
library(shiny)
library(DT)
library(plyr)
library(dplyr)
library(stringr)
library(d3Tree)
library(billboarder)
library(nbaR)
# This should define the root folder of the local copy of the git repository at:
# https://github.com/naturalis/Custom-databases-DNA-sequences, which is
# automatically defined correctly if we run the present code from within a
# local clone of the repo and have set the working directory to the script
# source (in RStudio: Session > Set working directory > To source file location)
setwd('..')
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
## Load species and synonyms from the NSR files, respectively
nsrSynonyms.file <- sprintf('%s/data/insert_files/nsr_synonym.csv', REPO_HOME)
nsrSynonyms <- read.csv(nsrSynonyms.file, encoding="UTF-8")
library(rmarkdown)
library(data.table)
library(taxizedb)
library(myTAI)
library(tidyr)
library(shiny)
library(DT)
library(plyr)
library(dplyr)
library(stringr)
library(d3Tree)
library(billboarder)
library(nbaR)
# This should define the root folder of the local copy of the git repository at:
# https://github.com/naturalis/Custom-databases-DNA-sequences, which is
# automatically defined correctly if we run the present code from within a
# local clone of the repo and have set the working directory to the script
# source (in RStudio: Session > Set working directory > To source file location)
setwd('..')
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
## Load species and synonyms from the NSR files, respectively
nsrSynonyms.file <- sprintf('%s/data/insert_files/nsr_synonyms.csv', REPO_HOME)
nsrSynonyms <- read.csv(nsrSynonyms.file, encoding="UTF-8")
library(rmarkdown)
library(data.table)
library(taxizedb)
library(myTAI)
library(tidyr)
library(shiny)
library(DT)
library(plyr)
library(dplyr)
library(stringr)
library(d3Tree)
library(billboarder)
library(nbaR)
# This should define the root folder of the local copy of the git repository at:
# https://github.com/naturalis/Custom-databases-DNA-sequences, which is
# automatically defined correctly if we run the present code from within a
# local clone of the repo and have set the working directory to the script
# source (in RStudio: Session > Set working directory > To source file location)
setwd('..')
REPO_HOME <- paste(dirname(getwd()), sep = "")
getwd()
## Load species and synonyms from the NSR files, respectively
nsrSynonyms.file <- sprintf('%s/data/insert_files/nsr_synonym.csv', REPO_HOME)
nsrSynonyms <- read.csv(nsrSynonyms.file, encoding="UTF-8")
nsrSpecies.file <- sprintf("%s/data/insert_files/nsr_species.csv", REPO_HOME)
nsrSpecies <- read.csv(nsrSpecies.file, encoding="UTF-8")
## Select species for taxon data retrieval
nsrIn <- tolower(nsrSpecies[, "species_name"])
head(nsrIn, 3)
## Query NSR taxon records (duration: ~40m)
## Method: nbaR 'taxon_query'
## Parameters: NSR source code and list of selected species
queryParams <- list("sourceSystem.code"="NSR")
nsrSpecimens <- data.frame()
for(x in 1:length(nsrIn)){
queryParams[["acceptedName.scientificNameGroup"]] <- nsrIn[x]
nsrSpecimens <- bind_rows(nsrSpecimens, taxon_query(queryParams))
}
## Access and extract required taxonomic fields from retrieved taxon records
nsrBackbone = data.frame()
for(x in 1:nrow(nsrSpecimens)){
tryCatch({
c.id=nsrSpecimens$sourceSystemId[x]
c.kingdom=nsrSpecimens$defaultClassification$kingdom[x]
c.phylum=nsrSpecimens$defaultClassification$phylum[x]
c.class=nsrSpecimens$defaultClassification$className[x]
c.order=nsrSpecimens$defaultClassification$order[x]
c.family=nsrSpecimens$defaultClassification$family[x]
c.genus=nsrSpecimens$defaultClassification$genus[x]
c.species=nsrSpecimens$acceptedName$specificEpithet[x]
c.authority=nsrSpecimens$acceptedName$authorshipVerbatim[x]
row <- data.frame(cbind(tax_id=c.id,kingdom=c.kingdom,phylum=c.phylum,class=c.class,
order=c.order,family=c.family,genus=c.genus,
species=paste(c.genus,c.species),identification_reference=c.authority))
nsrBackbone <- bind_rows(nsrBackbone, row)
}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
## Remove parenthesis around the authority for consistency across data sets
nsrBackbone$identification_reference = gsub("[()]", "", nsrBackbone$identification_reference)
head(nsrBackbone,3)
## Match taxonomic data to respective species ID, by species name
nsrBackbone <- left_join(nsrBackbone, nsrSpecies[1:2], by=c("species"="species_name")) %>%
.[,c(1,10,2,3,4,5,6,7,8,9)]
nsrBackbone <- unique(nsrBackbone)
## nsrBackbone after binding them to their species id by name (nsrSpecies), 10 columns (tax_id got added)
## Write NSR data to file
write.csv(nsrBackbone, file=sprintf('%s/data/insert_files/tree_nsr.csv', REPO_HOME),
row.names=FALSE, fileEncoding="utf-8")
## Clean up query variables
rm(x, row, queryParams, list = ls()[grep("^c.", ls())])
## Select species for taxon data retrieval
## Ensuring to select only binomial names
natIn <- unique(gsub("([A-Za-z]+).*", "\\1", nsrSpecies$species_name))
## Query Naturalis specimen records (duration: ~20m)
## Method: nbaR 'specimen_query'
## Parameters: CRS source code and list of selected species
queryParams <- list("sourceSystem.code"="CRS") #removed queryParams <- list(queryparams) before <- list(sourceS.. etc)
natSpecimens <- data.frame()
for(x in 1:length(natIn)){
queryParams[["identifications.defaultClassification.genus"]] <- natIn[x]
specimen_query(queryParams)
natSpecimens <- bind_rows(natSpecimens, specimen_query(queryParams))
}
## natSpecimens (13 rows, with @CRS!!)
## Access and extract required data fields from retrieved specimen records
natSpecies = data.frame()
for(x in 1:nrow(natSpecimens)){
tryCatch({
c.genus=natSpecimens$identifications[[x]]$defaultClassification$genus
c.species=natSpecimens$identifications[[x]]$defaultClassification$specificEpithet
c.count=natSpecimens$numberOfSpecimen[[x]]
c.id=natSpecimens$sourceSystemId[[x]]
row <- data.frame(cbind(species=paste(c.genus,c.species),counts=c.count,sequenceID=c.id))
natSpecies <- bind_rows(natSpecies, row)
}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
## Remove NAs
natSpecies$counts[is.na(natSpecies$counts)] <- 0
## Update data type and sum unique species record counts
natSpecies$counts <- as.numeric(as.character(natSpecies$counts))
natSpecies <- aggregate(natSpecies$counts,
by=list(natSpecies$species,natSpecies$sequenceID),sum)
## Rename columns
colnames(natSpecies) <- c("species", "sequenceID", "counts")
## Adopt respective taxonomic unit for synonymous names
natSpecies <- left_join(natSpecies, nsrSynonyms[2:3], by=c("species"="synonym_name"))
natSpecies <- left_join(natSpecies, nsrSpecies[1:2], by=c("species_id"))
natSpecies$species_name <- coalesce(natSpecies$species_name, natSpecies$species)
natSpecies <- natSpecies[,c(5,2,3)]
## Match species against the NSR
natCoverage <- merge(natSpecies, nsrSpecies[c(2:3)], by="species_name")
write.csv(nsrBackbone, file=sprintf('%s/data/exports/naturalis.csv', REPO_HOME),
row.names=FALSE, fileEncoding="utf-8")
## Clean up query variables
rm(x, row, queryParams, list = ls()[grep("^c.", ls())])
## Download taxonomic database (options: ncbi, itis, gbif, col, wfo)
## Used data source: NCBI
db_download_ncbi()
## Load species names from the NSR data set
taxidIn <- nsrSpecies[, "species_name"]
## Match species names to NCBI taxon IDs
taxidOut <- taxizedb::name2taxid(taxidIn, db="ncbi", out_type="summary")
head(taxidOut,3)
## NCBI taxon ID's
## Isolate taxon IDs from output, save as vector
treeIn <- as.vector(taxidOut$id)
head(treeIn,3)
## Only id's
## Retrieve taxonomic hierarchy for each taxon ID
treeOut <- taxizedb::classification(treeIn, db="ncbi", row=1, verbose=FALSE)
head(treeOut,3)
## Parse out the taxonomy levels/factors that you require
taxdata = data.frame()
for(x in 1:length(treeOut)){
tryCatch({
for(i in 1:length(treeOut[[x]][[1]])) {
c.tax_id=filter(treeOut[[x]])$id[[i]]
c.parent_tax_id=NULL
c.rank=filter(treeOut[[x]])$rank[[i]]
c.name=filter(treeOut[[x]])$name[[i]]
tryCatch({
c.parent_tax_id=filter(treeOut[[x]])$id[[i-1]]
}, error=function(e){c.parent_tax_id=NULL})
row <- data.frame(cbind(tax_id=c.tax_id,parent_tax_id=c.parent_tax_id,
rank=c.rank, name=c.name))
# Check if record exists
if (nrow(merge(row,taxdata))==0) {
taxdata <- bind_rows(taxdata, row)
}
}
}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
## Match hierarchies to NSR species names by taxon IDs
## (Accounting for use of synonymous names within NCBI)
ncbiBackbone <- left_join(taxdata, taxidOut, by=c("tax_id"="id"),
suffix=c("","_nsr")) %>%
left_join(., nsrSpecies[1:2], by=c("name_nsr" = "species_name")) %>%
.[, c(1,6,4,2,3)] # Reaarange columns, drop 'name_nsr' column
ncbiBackbone <- unique(ncbiBackbone)
## Write NCBI data to file
write.csv(ncbiBackbone, file=sprintf('%s/data/insert_files/tree_ncbi.csv', REPO_HOME),
row.names=FALSE, fileEncoding="utf-8", na="")
## Clean up query variables
rm(x, i, row, list = ls()[grep("^c.", ls())])
